{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b646aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layer.CSP_MB_Layers_test_1 import *\n",
    "from DataGenerator import load_data\n",
    "from models.model_1 import *\n",
    "from models.config_1 import CustomizeSmall, CustomizeLarge, MobileNetLarge, MobileNetSamll, EfficientNetB0\n",
    "from Flops import get_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb2f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型參數設定\n",
    "# MobileNetV3Large 、 MobileNetV3Small 、 EfficientNetB0 、 CustomizeLarge 、 CustomizeSmall\n",
    "backbone = 'CustomizeLarge'\n",
    "# None SE CBAM CA\n",
    "Attention_block_1 = None\n",
    "Attention_block_2 = 'SE'\n",
    "# Adam RMSprop CLR\n",
    "LR_mode = 'Adam'\n",
    "unfrozen = []\n",
    "\n",
    "# 圖片大小\n",
    "input_shape = None\n",
    "# 類別數\n",
    "num_classes = 0\n",
    "\n",
    "# 訓練參數\n",
    "BATCH_SIZE = 512\n",
    "epoch_1 = 150\n",
    "epoch_2 = 500\n",
    "Dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340271e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a178491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "Number of training samples:  40000\n",
      "Number of validation samples:  10000\n"
     ]
    }
   ],
   "source": [
    "# 100 Bird Species  or  325 Bird Species  or  cifar100 or cifar10\n",
    "Dataset = \"cifar10\"\n",
    "\n",
    "if Dataset == \"325 Bird Species\":\n",
    "    dir = \"./Dataset/325 Bird Species/\"\n",
    "    input_shape = (224,224,3)\n",
    "    num_classes = 325\n",
    "    trainset, valset, testset = load_data(Dataset, dir, input_shape, BATCH_SIZE)\n",
    "    \n",
    "elif Dataset == \"100 Bird Species\":\n",
    "    dir = \"./Dataset/100 Bird Species/\"\n",
    "    input_shape = (224,224,3)\n",
    "    num_classes = 100\n",
    "    trainset, valset, testset = load_data(Dataset, dir, input_shape, BATCH_SIZE)\n",
    "    \n",
    "elif Dataset == \"cifar100\":\n",
    "    input_shape = (32,32,3)\n",
    "    num_classes = 100\n",
    "    datagen_train, datagen_val, x_train, y_train, x_val, y_val, x_test, y_test = load_data(Dataset, '', input_shape, num_classes)\n",
    "    \n",
    "elif Dataset == \"cifar10\":\n",
    "    input_shape = (32,32,3)\n",
    "    num_classes = 10\n",
    "    datagen_train, datagen_val, x_train, y_train, x_val, y_val, x_test, y_test= load_data(Dataset, '', input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7febb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "if  backbone == \"CustomizeLarge\":\n",
    "    Specification, unfrozen = CustomizeLarge(Dataset)\n",
    "elif backbone == \"CustomizeSmall\":\n",
    "    Specification, unfrozen = CustomizeSmall(Dataset)\n",
    "elif backbone == 'MobileNetV3Large':\n",
    "    Specification, unfrozen = MobileNetLarge(Dataset)\n",
    "elif backbone == 'MobileNetV3Small':\n",
    "    Specification, unfrozen = MobileNetSamll(Dataset)\n",
    "elif backbone == 'EfficientNetB0':\n",
    "    Specification, unfrozen = EfficientNetB0(Dataset)\n",
    "\n",
    "base_model = build_base_model(input_shape, Attention_block_1, Attention_block_2, Specification)\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5127c17",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f16bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['Conv1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv1hardswish (HardSwish)     (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_conv1 (Conv2D)   (None, 32, 32, 8)    136         ['Conv1hardswish[0][0]']         \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_bn1 (BatchNormal  (None, 32, 32, 8)   32          ['CSP1_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_relu1 (Activatio  (None, 32, 32, 8)   0           ['CSP1_MBblock1_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_dw1 (DepthwiseCo  (None, 32, 32, 8)   80          ['CSP1_MBblock1_relu1[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_bn2 (BatchNormal  (None, 32, 32, 8)   32          ['CSP1_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_relu2 (Activatio  (None, 32, 32, 8)   0           ['CSP1_MBblock1_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_conv2 (Conv2D)   (None, 32, 32, 8)    72          ['CSP1_MBblock1_relu2[0][0]']    \n",
      "                                                                                                  \n",
      " CSP1_conv1 (Conv2D)            (None, 32, 32, 8)    136         ['Conv1hardswish[0][0]']         \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_bn3 (BatchNormal  (None, 32, 32, 8)   32          ['CSP1_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP1_bn1 (BatchNormalization)  (None, 32, 32, 8)    32          ['CSP1_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP1_MBblock1_relu3 (Activatio  (None, 32, 32, 8)   0           ['CSP1_MBblock1_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP1_relu3 (Activation)        (None, 32, 32, 8)    0           ['CSP1_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP1_concatenate (Concatenate)  (None, 32, 32, 16)  0           ['CSP1_MBblock1_relu3[0][0]',    \n",
      "                                                                  'CSP1_relu3[0][0]']             \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_conv1 (Conv2D)   (None, 32, 32, 32)   544         ['CSP1_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_bn1 (BatchNormal  (None, 32, 32, 32)  128         ['CSP2_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_relu1 (Activatio  (None, 32, 32, 32)  0           ['CSP2_MBblock1_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_dw1 (DepthwiseCo  (None, 32, 32, 32)  320         ['CSP2_MBblock1_relu1[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_bn2 (BatchNormal  (None, 32, 32, 32)  128         ['CSP2_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_relu2 (Activatio  (None, 32, 32, 32)  0           ['CSP2_MBblock1_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_conv2 (Conv2D)   (None, 32, 32, 12)   396         ['CSP2_MBblock1_relu2[0][0]']    \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_bn3 (BatchNormal  (None, 32, 32, 12)  48          ['CSP2_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_MBblock1_relu3 (Activatio  (None, 32, 32, 12)  0           ['CSP2_MBblock1_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_conv1 (Conv2D)   (None, 32, 32, 36)   468         ['CSP2_MBblock1_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_bn1 (BatchNormal  (None, 32, 32, 36)  144         ['CSP2_MBblock2_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_relu1 (Activatio  (None, 32, 32, 36)  0           ['CSP2_MBblock2_bn1[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_dw1 (DepthwiseCo  (None, 32, 32, 36)  360         ['CSP2_MBblock2_relu1[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_bn2 (BatchNormal  (None, 32, 32, 36)  144         ['CSP2_MBblock2_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_relu2 (Activatio  (None, 32, 32, 36)  0           ['CSP2_MBblock2_bn2[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_conv2 (Conv2D)   (None, 32, 32, 12)   444         ['CSP2_MBblock2_relu2[0][0]']    \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_bn3 (BatchNormal  (None, 32, 32, 12)  48          ['CSP2_MBblock2_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP2_conv1 (Conv2D)            (None, 32, 32, 12)   204         ['CSP1_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_relu3 (Activatio  (None, 32, 32, 12)  0           ['CSP2_MBblock2_bn3[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP2_bn1 (BatchNormalization)  (None, 32, 32, 12)   48          ['CSP2_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP2_MBblock2_stochastic_depth  (None, 32, 32, 12)  0           ['CSP2_MBblock1_relu3[0][0]',    \n",
      "  (StochasticDepth)                                               'CSP2_MBblock2_relu3[0][0]']    \n",
      "                                                                                                  \n",
      " CSP2_relu3 (Activation)        (None, 32, 32, 12)   0           ['CSP2_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP2_concatenate (Concatenate)  (None, 32, 32, 24)  0           ['CSP2_MBblock2_stochastic_depth[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'CSP2_relu3[0][0]']             \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_conv1 (Conv2D)   (None, 32, 32, 36)   900         ['CSP2_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_bn1 (BatchNormal  (None, 32, 32, 36)  144         ['CSP3_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_hardswish1 (Hard  (None, 32, 32, 36)  0           ['CSP3_MBblock1_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_dw1 (DepthwiseCo  (None, 16, 16, 36)  936         ['CSP3_MBblock1_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_bn2 (BatchNormal  (None, 16, 16, 36)  144         ['CSP3_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_hardswish2 (Hard  (None, 16, 16, 36)  0           ['CSP3_MBblock1_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_conv2 (Conv2D)   (None, 16, 16, 20)   740         ['CSP3_MBblock1_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_bn3 (BatchNormal  (None, 16, 16, 20)  80          ['CSP3_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock1_hardswish3 (Hard  (None, 16, 16, 20)  0           ['CSP3_MBblock1_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_conv1 (Conv2D)   (None, 16, 16, 60)   1260        ['CSP3_MBblock1_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_bn1 (BatchNormal  (None, 16, 16, 60)  240         ['CSP3_MBblock2_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_hardswish1 (Hard  (None, 16, 16, 60)  0           ['CSP3_MBblock2_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_dw1 (DepthwiseCo  (None, 16, 16, 60)  1560        ['CSP3_MBblock2_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_bn2 (BatchNormal  (None, 16, 16, 60)  240         ['CSP3_MBblock2_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_hardswish2 (Hard  (None, 16, 16, 60)  0           ['CSP3_MBblock2_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_conv2 (Conv2D)   (None, 16, 16, 20)   1220        ['CSP3_MBblock2_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_bn3 (BatchNormal  (None, 16, 16, 20)  80          ['CSP3_MBblock2_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_hardswish3 (Hard  (None, 16, 16, 20)  0           ['CSP3_MBblock2_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock2_stochastic_depth  (None, 16, 16, 20)  0           ['CSP3_MBblock1_hardswish3[0][0]'\n",
      "  (StochasticDepth)                                              , 'CSP3_MBblock2_hardswish3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_conv1 (Conv2D)   (None, 16, 16, 60)   1260        ['CSP3_MBblock2_stochastic_depth[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_bn1 (BatchNormal  (None, 16, 16, 60)  240         ['CSP3_MBblock3_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_hardswish1 (Hard  (None, 16, 16, 60)  0           ['CSP3_MBblock3_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_dw1 (DepthwiseCo  (None, 16, 16, 60)  1560        ['CSP3_MBblock3_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_bn2 (BatchNormal  (None, 16, 16, 60)  240         ['CSP3_MBblock3_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_zoom (DepthwiseConv2D)    (None, 16, 16, 24)   120         ['CSP2_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_hardswish2 (Hard  (None, 16, 16, 60)  0           ['CSP3_MBblock3_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_zoom_bn (BatchNormalizati  (None, 16, 16, 24)  96          ['CSP3_zoom[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_conv2 (Conv2D)   (None, 16, 16, 20)   1220        ['CSP3_MBblock3_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP3_zoom_hardswish (HardSwish  (None, 16, 16, 24)  0           ['CSP3_zoom_bn[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_bn3 (BatchNormal  (None, 16, 16, 20)  80          ['CSP3_MBblock3_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP3_conv1 (Conv2D)            (None, 16, 16, 20)   500         ['CSP3_zoom_hardswish[0][0]']    \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_hardswish3 (Hard  (None, 16, 16, 20)  0           ['CSP3_MBblock3_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_bn1 (BatchNormalization)  (None, 16, 16, 20)   80          ['CSP3_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP3_MBblock3_stochastic_depth  (None, 16, 16, 20)  0           ['CSP3_MBblock2_stochastic_depth[\n",
      "  (StochasticDepth)                                              0][0]',                          \n",
      "                                                                  'CSP3_MBblock3_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP3_hardswish1 (HardSwish)    (None, 16, 16, 20)   0           ['CSP3_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP3_concatenate (Concatenate)  (None, 16, 16, 40)  0           ['CSP3_MBblock3_stochastic_depth[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'CSP3_hardswish1[0][0]']        \n",
      "                                                                                                  \n",
      " CSP3_SE_GAP (GlobalAveragePool  (None, 40)          0           ['CSP3_concatenate[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " CSP3_SE_Dense1 (Dense)         (None, 10)           410         ['CSP3_SE_GAP[0][0]']            \n",
      "                                                                                                  \n",
      " CSP3_SE_bn1 (BatchNormalizatio  (None, 10)          40          ['CSP3_SE_Dense1[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP3_SE_hardswish (HardSwish)  (None, 10)           0           ['CSP3_SE_bn1[0][0]']            \n",
      "                                                                                                  \n",
      " CSP3_SE_Dense2 (Dense)         (None, 40)           440         ['CSP3_SE_hardswish[0][0]']      \n",
      "                                                                                                  \n",
      " CSP3_SE_bn2 (BatchNormalizatio  (None, 40)          160         ['CSP3_SE_Dense2[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP3_SE_hardsigmoid (HardSigmo  (None, 40)          0           ['CSP3_SE_bn2[0][0]']            \n",
      " id)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1, 1, 40)     0           ['CSP3_SE_hardsigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " CSP3_SE_Multiply (Multiply)    (None, 16, 16, 40)   0           ['CSP3_concatenate[0][0]',       \n",
      "                                                                  'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_conv1 (Conv2D)   (None, 16, 16, 120)  4920        ['CSP3_SE_Multiply[0][0]']       \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_bn1 (BatchNormal  (None, 16, 16, 120)  480        ['CSP4_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_hardswish1 (Hard  (None, 16, 16, 120)  0          ['CSP4_MBblock1_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_dw1 (DepthwiseCo  (None, 8, 8, 120)   3120        ['CSP4_MBblock1_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_bn2 (BatchNormal  (None, 8, 8, 120)   480         ['CSP4_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_hardswish2 (Hard  (None, 8, 8, 120)   0           ['CSP4_MBblock1_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_conv2 (Conv2D)   (None, 8, 8, 40)     4840        ['CSP4_MBblock1_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_bn3 (BatchNormal  (None, 8, 8, 40)    160         ['CSP4_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock1_hardswish3 (Hard  (None, 8, 8, 40)    0           ['CSP4_MBblock1_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_conv1 (Conv2D)   (None, 8, 8, 100)    4100        ['CSP4_MBblock1_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_bn1 (BatchNormal  (None, 8, 8, 100)   400         ['CSP4_MBblock2_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_hardswish1 (Hard  (None, 8, 8, 100)   0           ['CSP4_MBblock2_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_dw1 (DepthwiseCo  (None, 8, 8, 100)   2600        ['CSP4_MBblock2_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_bn2 (BatchNormal  (None, 8, 8, 100)   400         ['CSP4_MBblock2_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_hardswish2 (Hard  (None, 8, 8, 100)   0           ['CSP4_MBblock2_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_conv2 (Conv2D)   (None, 8, 8, 40)     4040        ['CSP4_MBblock2_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_bn3 (BatchNormal  (None, 8, 8, 40)    160         ['CSP4_MBblock2_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_hardswish3 (Hard  (None, 8, 8, 40)    0           ['CSP4_MBblock2_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock2_stochastic_depth  (None, 8, 8, 40)    0           ['CSP4_MBblock1_hardswish3[0][0]'\n",
      "  (StochasticDepth)                                              , 'CSP4_MBblock2_hardswish3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_conv1 (Conv2D)   (None, 8, 8, 92)     3772        ['CSP4_MBblock2_stochastic_depth[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_bn1 (BatchNormal  (None, 8, 8, 92)    368         ['CSP4_MBblock3_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_hardswish1 (Hard  (None, 8, 8, 92)    0           ['CSP4_MBblock3_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_dw1 (DepthwiseCo  (None, 8, 8, 92)    2392        ['CSP4_MBblock3_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_bn2 (BatchNormal  (None, 8, 8, 92)    368         ['CSP4_MBblock3_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_hardswish2 (Hard  (None, 8, 8, 92)    0           ['CSP4_MBblock3_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_conv2 (Conv2D)   (None, 8, 8, 40)     3720        ['CSP4_MBblock3_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_bn3 (BatchNormal  (None, 8, 8, 40)    160         ['CSP4_MBblock3_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_hardswish3 (Hard  (None, 8, 8, 40)    0           ['CSP4_MBblock3_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock3_stochastic_depth  (None, 8, 8, 40)    0           ['CSP4_MBblock2_stochastic_depth[\n",
      "  (StochasticDepth)                                              0][0]',                          \n",
      "                                                                  'CSP4_MBblock3_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_conv1 (Conv2D)   (None, 8, 8, 92)     3772        ['CSP4_MBblock3_stochastic_depth[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_bn1 (BatchNormal  (None, 8, 8, 92)    368         ['CSP4_MBblock4_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_hardswish1 (Hard  (None, 8, 8, 92)    0           ['CSP4_MBblock4_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_dw1 (DepthwiseCo  (None, 8, 8, 92)    2392        ['CSP4_MBblock4_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_bn2 (BatchNormal  (None, 8, 8, 92)    368         ['CSP4_MBblock4_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_zoom (DepthwiseConv2D)    (None, 8, 8, 40)     200         ['CSP3_SE_Multiply[0][0]']       \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_hardswish2 (Hard  (None, 8, 8, 92)    0           ['CSP4_MBblock4_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_zoom_bn (BatchNormalizati  (None, 8, 8, 40)    160         ['CSP4_zoom[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_conv2 (Conv2D)   (None, 8, 8, 40)     3720        ['CSP4_MBblock4_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_zoom_hardswish (HardSwish  (None, 8, 8, 40)    0           ['CSP4_zoom_bn[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_bn3 (BatchNormal  (None, 8, 8, 40)    160         ['CSP4_MBblock4_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP4_conv1 (Conv2D)            (None, 8, 8, 40)     1640        ['CSP4_zoom_hardswish[0][0]']    \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_hardswish3 (Hard  (None, 8, 8, 40)    0           ['CSP4_MBblock4_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP4_bn1 (BatchNormalization)  (None, 8, 8, 40)     160         ['CSP4_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP4_MBblock4_stochastic_depth  (None, 8, 8, 40)    0           ['CSP4_MBblock3_stochastic_depth[\n",
      "  (StochasticDepth)                                              0][0]',                          \n",
      "                                                                  'CSP4_MBblock4_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP4_hardswish1 (HardSwish)    (None, 8, 8, 40)     0           ['CSP4_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP4_concatenate (Concatenate)  (None, 8, 8, 80)    0           ['CSP4_MBblock4_stochastic_depth[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'CSP4_hardswish1[0][0]']        \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_conv1 (Conv2D)   (None, 8, 8, 240)    19440       ['CSP4_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_bn1 (BatchNormal  (None, 8, 8, 240)   960         ['CSP5_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_hardswish1 (Hard  (None, 8, 8, 240)   0           ['CSP5_MBblock1_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_dw1 (DepthwiseCo  (None, 8, 8, 240)   6240        ['CSP5_MBblock1_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_bn2 (BatchNormal  (None, 8, 8, 240)   960         ['CSP5_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_hardswish2 (Hard  (None, 8, 8, 240)   0           ['CSP5_MBblock1_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_conv2 (Conv2D)   (None, 8, 8, 56)     13496       ['CSP5_MBblock1_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_bn3 (BatchNormal  (None, 8, 8, 56)    224         ['CSP5_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_MBblock1_hardswish3 (Hard  (None, 8, 8, 56)    0           ['CSP5_MBblock1_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_conv1 (Conv2D)   (None, 8, 8, 336)    19152       ['CSP5_MBblock1_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_bn1 (BatchNormal  (None, 8, 8, 336)   1344        ['CSP5_MBblock2_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_hardswish1 (Hard  (None, 8, 8, 336)   0           ['CSP5_MBblock2_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_dw1 (DepthwiseCo  (None, 8, 8, 336)   8736        ['CSP5_MBblock2_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_bn2 (BatchNormal  (None, 8, 8, 336)   1344        ['CSP5_MBblock2_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_hardswish2 (Hard  (None, 8, 8, 336)   0           ['CSP5_MBblock2_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_conv2 (Conv2D)   (None, 8, 8, 56)     18872       ['CSP5_MBblock2_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_bn3 (BatchNormal  (None, 8, 8, 56)    224         ['CSP5_MBblock2_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP5_conv1 (Conv2D)            (None, 8, 8, 56)     4536        ['CSP4_concatenate[0][0]']       \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_hardswish3 (Hard  (None, 8, 8, 56)    0           ['CSP5_MBblock2_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_bn1 (BatchNormalization)  (None, 8, 8, 56)     224         ['CSP5_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP5_MBblock2_stochastic_depth  (None, 8, 8, 56)    0           ['CSP5_MBblock1_hardswish3[0][0]'\n",
      "  (StochasticDepth)                                              , 'CSP5_MBblock2_hardswish3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " CSP5_hardswish1 (HardSwish)    (None, 8, 8, 56)     0           ['CSP5_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP5_concatenate (Concatenate)  (None, 8, 8, 112)   0           ['CSP5_MBblock2_stochastic_depth[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'CSP5_hardswish1[0][0]']        \n",
      "                                                                                                  \n",
      " CSP5_SE_GAP (GlobalAveragePool  (None, 112)         0           ['CSP5_concatenate[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " CSP5_SE_Dense1 (Dense)         (None, 28)           3164        ['CSP5_SE_GAP[0][0]']            \n",
      "                                                                                                  \n",
      " CSP5_SE_bn1 (BatchNormalizatio  (None, 28)          112         ['CSP5_SE_Dense1[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP5_SE_hardswish (HardSwish)  (None, 28)           0           ['CSP5_SE_bn1[0][0]']            \n",
      "                                                                                                  \n",
      " CSP5_SE_Dense2 (Dense)         (None, 112)          3248        ['CSP5_SE_hardswish[0][0]']      \n",
      "                                                                                                  \n",
      " CSP5_SE_bn2 (BatchNormalizatio  (None, 112)         448         ['CSP5_SE_Dense2[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP5_SE_hardsigmoid (HardSigmo  (None, 112)         0           ['CSP5_SE_bn2[0][0]']            \n",
      " id)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 1, 1, 112)    0           ['CSP5_SE_hardsigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " CSP5_SE_Multiply (Multiply)    (None, 8, 8, 112)    0           ['CSP5_concatenate[0][0]',       \n",
      "                                                                  'tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_conv1 (Conv2D)   (None, 8, 8, 336)    37968       ['CSP5_SE_Multiply[0][0]']       \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_bn1 (BatchNormal  (None, 8, 8, 336)   1344        ['CSP6_MBblock1_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_hardswish1 (Hard  (None, 8, 8, 336)   0           ['CSP6_MBblock1_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_dw1 (DepthwiseCo  (None, 4, 4, 336)   8736        ['CSP6_MBblock1_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_bn2 (BatchNormal  (None, 4, 4, 336)   1344        ['CSP6_MBblock1_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_hardswish2 (Hard  (None, 4, 4, 336)   0           ['CSP6_MBblock1_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_conv2 (Conv2D)   (None, 4, 4, 80)     26960       ['CSP6_MBblock1_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_bn3 (BatchNormal  (None, 4, 4, 80)    320         ['CSP6_MBblock1_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock1_hardswish3 (Hard  (None, 4, 4, 80)    0           ['CSP6_MBblock1_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_conv1 (Conv2D)   (None, 4, 4, 480)    38880       ['CSP6_MBblock1_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_bn1 (BatchNormal  (None, 4, 4, 480)   1920        ['CSP6_MBblock2_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_hardswish1 (Hard  (None, 4, 4, 480)   0           ['CSP6_MBblock2_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_dw1 (DepthwiseCo  (None, 4, 4, 480)   12480       ['CSP6_MBblock2_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_bn2 (BatchNormal  (None, 4, 4, 480)   1920        ['CSP6_MBblock2_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_hardswish2 (Hard  (None, 4, 4, 480)   0           ['CSP6_MBblock2_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_conv2 (Conv2D)   (None, 4, 4, 80)     38480       ['CSP6_MBblock2_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_bn3 (BatchNormal  (None, 4, 4, 80)    320         ['CSP6_MBblock2_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_hardswish3 (Hard  (None, 4, 4, 80)    0           ['CSP6_MBblock2_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock2_stochastic_depth  (None, 4, 4, 80)    0           ['CSP6_MBblock1_hardswish3[0][0]'\n",
      "  (StochasticDepth)                                              , 'CSP6_MBblock2_hardswish3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_conv1 (Conv2D)   (None, 4, 4, 480)    38880       ['CSP6_MBblock2_stochastic_depth[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_bn1 (BatchNormal  (None, 4, 4, 480)   1920        ['CSP6_MBblock3_conv1[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_hardswish1 (Hard  (None, 4, 4, 480)   0           ['CSP6_MBblock3_bn1[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_dw1 (DepthwiseCo  (None, 4, 4, 480)   12480       ['CSP6_MBblock3_hardswish1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_bn2 (BatchNormal  (None, 4, 4, 480)   1920        ['CSP6_MBblock3_dw1[0][0]']      \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_zoom (DepthwiseConv2D)    (None, 4, 4, 112)    560         ['CSP5_SE_Multiply[0][0]']       \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_hardswish2 (Hard  (None, 4, 4, 480)   0           ['CSP6_MBblock3_bn2[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_zoom_bn (BatchNormalizati  (None, 4, 4, 112)   448         ['CSP6_zoom[0][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_conv2 (Conv2D)   (None, 4, 4, 80)     38480       ['CSP6_MBblock3_hardswish2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP6_zoom_hardswish (HardSwish  (None, 4, 4, 112)   0           ['CSP6_zoom_bn[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_bn3 (BatchNormal  (None, 4, 4, 80)    320         ['CSP6_MBblock3_conv2[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " CSP6_conv1 (Conv2D)            (None, 4, 4, 80)     9040        ['CSP6_zoom_hardswish[0][0]']    \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_hardswish3 (Hard  (None, 4, 4, 80)    0           ['CSP6_MBblock3_bn3[0][0]']      \n",
      " Swish)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_bn1 (BatchNormalization)  (None, 4, 4, 80)     320         ['CSP6_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " CSP6_MBblock3_stochastic_depth  (None, 4, 4, 80)    0           ['CSP6_MBblock2_stochastic_depth[\n",
      "  (StochasticDepth)                                              0][0]',                          \n",
      "                                                                  'CSP6_MBblock3_hardswish3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " CSP6_hardswish1 (HardSwish)    (None, 4, 4, 80)     0           ['CSP6_bn1[0][0]']               \n",
      "                                                                                                  \n",
      " CSP6_concatenate (Concatenate)  (None, 4, 4, 160)   0           ['CSP6_MBblock3_stochastic_depth[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'CSP6_hardswish1[0][0]']        \n",
      "                                                                                                  \n",
      " CSP6_SE_GAP (GlobalAveragePool  (None, 160)         0           ['CSP6_concatenate[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " CSP6_SE_Dense1 (Dense)         (None, 40)           6440        ['CSP6_SE_GAP[0][0]']            \n",
      "                                                                                                  \n",
      " CSP6_SE_bn1 (BatchNormalizatio  (None, 40)          160         ['CSP6_SE_Dense1[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP6_SE_hardswish (HardSwish)  (None, 40)           0           ['CSP6_SE_bn1[0][0]']            \n",
      "                                                                                                  \n",
      " CSP6_SE_Dense2 (Dense)         (None, 160)          6560        ['CSP6_SE_hardswish[0][0]']      \n",
      "                                                                                                  \n",
      " CSP6_SE_bn2 (BatchNormalizatio  (None, 160)         640         ['CSP6_SE_Dense2[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " CSP6_SE_hardsigmoid (HardSigmo  (None, 160)         0           ['CSP6_SE_bn2[0][0]']            \n",
      " id)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 1, 1, 160)    0           ['CSP6_SE_hardsigmoid[0][0]']    \n",
      "                                                                                                  \n",
      " CSP6_SE_Multiply (Multiply)    (None, 4, 4, 160)    0           ['CSP6_concatenate[0][0]',       \n",
      "                                                                  'tf.reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 4, 4, 960)    154560      ['CSP6_SE_Multiply[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 4, 4, 960)   3840        ['Conv2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " Conv2hardswish (HardSwish)     (None, 4, 4, 960)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " Conv3 (Conv2D)                 (None, 4, 4, 1280)   1230080     ['Conv2hardswish[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 4, 1280)  5120        ['Conv3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " Conv3hardswish (HardSwish)     (None, 4, 4, 1280)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['Conv3hardswish[0][0]']         \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " predition_head_classification   (None, 10)          12810       ['dropout[0][0]']                \n",
      " (Dense)                                                                                          \n",
      "                                                                                                  \n",
      " predition_softmax (Activation)  (None, 10)          0           ['predition_head_classification[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,865,872\n",
      "Trainable params: 1,848,556\n",
      "Non-trainable params: 17,316\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\Anaconda3\\envs\\tf28\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "The FLOPs is:90553347\n"
     ]
    }
   ],
   "source": [
    "predtions = predictions_head(base_model, num_classes, Dropout_rate)\n",
    "model = build_model(base_model, predtions)\n",
    "model.summary()\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ca2195",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11910179",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 0.00025\n",
    "MAX_LR = 0.001\n",
    "if Dataset == \"325 Bird Species\" or Dataset == \"100 Bird Species\":\n",
    "    steps_per_epoch = trainset.samples // BATCH_SIZE\n",
    "elif Dataset == \"cifar10\" or Dataset == \"cifar100\":\n",
    "    steps_per_epoch = len(x_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983f10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "optimizer = optimizer_set(LR_mode=LR_mode,\n",
    "                          INIT_LR=INIT_LR,\n",
    "                          MAX_LR=MAX_LR,\n",
    "                          steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "loss = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4e40a",
   "metadata": {},
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c9f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "checkpoint_path = f'weights_V2/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}/'+ \"cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_best_only=True, \n",
    "    mode='max',\n",
    "    save_freq='epoch'\n",
    "    )\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}/\",\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=False,\n",
    "                          update_freq=\"epoch\",\n",
    "                          profile_batch=2,\n",
    "                          embeddings_freq=0,\n",
    "                          embeddings_metadata=None,)\n",
    "\n",
    "callbacks = [tensorboard, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7ecd2",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e127d23",
   "metadata": {},
   "source": [
    "- 如果選擇的是自定義模型，則需要從頭開始訓練整個模型\n",
    "- 若選擇其他模型，則直接轉至Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c2950",
   "metadata": {},
   "source": [
    "## Training-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1af4114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 2.2520 - accuracy: 0.2479\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0001.ckpt\n",
      "79/79 [==============================] - 25s 193ms/step - loss: 2.2520 - accuracy: 0.2479 - val_loss: 2.4022 - val_accuracy: 0.1000\n",
      "Epoch 2/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.9608 - accuracy: 0.3589\n",
      "Epoch 2: val_accuracy did not improve from 0.10000\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 1.9608 - accuracy: 0.3589 - val_loss: 2.4109 - val_accuracy: 0.1000\n",
      "Epoch 3/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.8030 - accuracy: 0.4320\n",
      "Epoch 3: val_accuracy did not improve from 0.10000\n",
      "79/79 [==============================] - 13s 167ms/step - loss: 1.8030 - accuracy: 0.4320 - val_loss: 2.4211 - val_accuracy: 0.1000\n",
      "Epoch 4/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.6912 - accuracy: 0.4867\n",
      "Epoch 4: val_accuracy did not improve from 0.10000\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 1.6912 - accuracy: 0.4867 - val_loss: 2.4495 - val_accuracy: 0.1000\n",
      "Epoch 5/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 0.5370\n",
      "Epoch 5: val_accuracy did not improve from 0.10000\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 1.5902 - accuracy: 0.5370 - val_loss: 2.5281 - val_accuracy: 0.1000\n",
      "Epoch 6/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.5198 - accuracy: 0.5706\n",
      "Epoch 6: val_accuracy improved from 0.10000 to 0.10520, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0006.ckpt\n",
      "79/79 [==============================] - 13s 157ms/step - loss: 1.5198 - accuracy: 0.5706 - val_loss: 2.8906 - val_accuracy: 0.1052\n",
      "Epoch 7/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.4288 - accuracy: 0.6136\n",
      "Epoch 7: val_accuracy did not improve from 0.10520\n",
      "79/79 [==============================] - 13s 157ms/step - loss: 1.4288 - accuracy: 0.6136 - val_loss: 3.3093 - val_accuracy: 0.1000\n",
      "Epoch 8/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3700 - accuracy: 0.6417\n",
      "Epoch 8: val_accuracy improved from 0.10520 to 0.23610, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0008.ckpt\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 1.3700 - accuracy: 0.6417 - val_loss: 2.4343 - val_accuracy: 0.2361\n",
      "Epoch 9/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.3287 - accuracy: 0.6603\n",
      "Epoch 9: val_accuracy improved from 0.23610 to 0.62740, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0009.ckpt\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 1.3287 - accuracy: 0.6603 - val_loss: 1.3939 - val_accuracy: 0.6274\n",
      "Epoch 10/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.2664 - accuracy: 0.6901\n",
      "Epoch 10: val_accuracy improved from 0.62740 to 0.65410, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0010.ckpt\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 1.2664 - accuracy: 0.6901 - val_loss: 1.3408 - val_accuracy: 0.6541\n",
      "Epoch 11/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.2195 - accuracy: 0.7083\n",
      "Epoch 11: val_accuracy did not improve from 0.65410\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 1.2195 - accuracy: 0.7084 - val_loss: 1.9236 - val_accuracy: 0.4585\n",
      "Epoch 12/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1850 - accuracy: 0.7237\n",
      "Epoch 12: val_accuracy improved from 0.65410 to 0.65750, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0012.ckpt\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 1.1850 - accuracy: 0.7237 - val_loss: 1.3526 - val_accuracy: 0.6575\n",
      "Epoch 13/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1509 - accuracy: 0.7419\n",
      "Epoch 13: val_accuracy did not improve from 0.65750\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.1509 - accuracy: 0.7419 - val_loss: 1.4442 - val_accuracy: 0.6354\n",
      "Epoch 14/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.1205 - accuracy: 0.7533\n",
      "Epoch 14: val_accuracy improved from 0.65750 to 0.69990, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0014.ckpt\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 1.1205 - accuracy: 0.7533 - val_loss: 1.2559 - val_accuracy: 0.6999\n",
      "Epoch 15/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0890 - accuracy: 0.7686\n",
      "Epoch 15: val_accuracy did not improve from 0.69990\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 1.0890 - accuracy: 0.7686 - val_loss: 1.2626 - val_accuracy: 0.6954\n",
      "Epoch 16/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0636 - accuracy: 0.7800\n",
      "Epoch 16: val_accuracy improved from 0.69990 to 0.72140, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0016.ckpt\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 1.0636 - accuracy: 0.7800 - val_loss: 1.2010 - val_accuracy: 0.7214\n",
      "Epoch 17/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0455 - accuracy: 0.7843\n",
      "Epoch 17: val_accuracy did not improve from 0.72140\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 1.0455 - accuracy: 0.7843 - val_loss: 1.3175 - val_accuracy: 0.6787\n",
      "Epoch 18/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.8005\n",
      "Epoch 18: val_accuracy did not improve from 0.72140\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.0131 - accuracy: 0.8005 - val_loss: 1.2861 - val_accuracy: 0.6920\n",
      "Epoch 19/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 1.0002 - accuracy: 0.8034\n",
      "Epoch 19: val_accuracy did not improve from 0.72140\n",
      "79/79 [==============================] - 12s 148ms/step - loss: 1.0003 - accuracy: 0.8034 - val_loss: 1.2346 - val_accuracy: 0.7068\n",
      "Epoch 20/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0513 - accuracy: 0.7823\n",
      "Epoch 20: val_accuracy did not improve from 0.72140\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 1.0513 - accuracy: 0.7823 - val_loss: 1.7102 - val_accuracy: 0.5266\n",
      "Epoch 21/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 1.0238 - accuracy: 0.7951\n",
      "Epoch 21: val_accuracy improved from 0.72140 to 0.74990, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0021.ckpt\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 1.0238 - accuracy: 0.7951 - val_loss: 1.1263 - val_accuracy: 0.7499\n",
      "Epoch 22/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9763 - accuracy: 0.8142\n",
      "Epoch 22: val_accuracy improved from 0.74990 to 0.77310, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0022.ckpt\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 0.9763 - accuracy: 0.8142 - val_loss: 1.0714 - val_accuracy: 0.7731\n",
      "Epoch 23/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.8206\n",
      "Epoch 23: val_accuracy improved from 0.77310 to 0.79940, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0023.ckpt\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.9643 - accuracy: 0.8206 - val_loss: 0.9980 - val_accuracy: 0.7994\n",
      "Epoch 24/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9412 - accuracy: 0.8306\n",
      "Epoch 24: val_accuracy did not improve from 0.79940\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.9412 - accuracy: 0.8306 - val_loss: 1.1381 - val_accuracy: 0.7510\n",
      "Epoch 25/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9245 - accuracy: 0.8383\n",
      "Epoch 25: val_accuracy improved from 0.79940 to 0.79970, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0025.ckpt\n",
      "79/79 [==============================] - 13s 166ms/step - loss: 0.9245 - accuracy: 0.8383 - val_loss: 1.0235 - val_accuracy: 0.7997\n",
      "Epoch 26/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9191 - accuracy: 0.8419\n",
      "Epoch 26: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.9191 - accuracy: 0.8419 - val_loss: 1.1151 - val_accuracy: 0.7553\n",
      "Epoch 27/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.9210 - accuracy: 0.8402\n",
      "Epoch 27: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.9210 - accuracy: 0.8402 - val_loss: 1.0199 - val_accuracy: 0.7938\n",
      "Epoch 28/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.8524\n",
      "Epoch 28: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 148ms/step - loss: 0.8929 - accuracy: 0.8524 - val_loss: 1.0309 - val_accuracy: 0.7859\n",
      "Epoch 29/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8827 - accuracy: 0.8560\n",
      "Epoch 29: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.8827 - accuracy: 0.8560 - val_loss: 1.0212 - val_accuracy: 0.7953\n",
      "Epoch 30/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.8594\n",
      "Epoch 30: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.8783 - accuracy: 0.8594 - val_loss: 1.0197 - val_accuracy: 0.7976\n",
      "Epoch 31/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.8612\n",
      "Epoch 31: val_accuracy did not improve from 0.79970\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.8723 - accuracy: 0.8612 - val_loss: 1.1262 - val_accuracy: 0.7599\n",
      "Epoch 32/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8570 - accuracy: 0.8707\n",
      "Epoch 32: val_accuracy improved from 0.79970 to 0.80400, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0032.ckpt\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 0.8570 - accuracy: 0.8707 - val_loss: 0.9983 - val_accuracy: 0.8040\n",
      "Epoch 33/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8563 - accuracy: 0.8687\n",
      "Epoch 33: val_accuracy improved from 0.80400 to 0.81940, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0033.ckpt\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 0.8563 - accuracy: 0.8687 - val_loss: 0.9680 - val_accuracy: 0.8194\n",
      "Epoch 34/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.8709\n",
      "Epoch 34: val_accuracy improved from 0.81940 to 0.82040, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0034.ckpt\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 0.8525 - accuracy: 0.8709 - val_loss: 0.9649 - val_accuracy: 0.8204\n",
      "Epoch 35/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8323 - accuracy: 0.8795\n",
      "Epoch 35: val_accuracy improved from 0.82040 to 0.82100, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0035.ckpt\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 0.8323 - accuracy: 0.8795 - val_loss: 0.9631 - val_accuracy: 0.8210\n",
      "Epoch 36/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8377 - accuracy: 0.8749\n",
      "Epoch 36: val_accuracy improved from 0.82100 to 0.82470, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0036.ckpt\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.8377 - accuracy: 0.8749 - val_loss: 0.9526 - val_accuracy: 0.8247\n",
      "Epoch 37/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8256 - accuracy: 0.8817\n",
      "Epoch 37: val_accuracy did not improve from 0.82470\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.8256 - accuracy: 0.8817 - val_loss: 0.9618 - val_accuracy: 0.8185\n",
      "Epoch 38/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8176 - accuracy: 0.8861\n",
      "Epoch 38: val_accuracy did not improve from 0.82470\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.8176 - accuracy: 0.8861 - val_loss: 1.0037 - val_accuracy: 0.8063\n",
      "Epoch 39/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8231 - accuracy: 0.8830\n",
      "Epoch 39: val_accuracy improved from 0.82470 to 0.83100, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0039.ckpt\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.8231 - accuracy: 0.8830 - val_loss: 0.9396 - val_accuracy: 0.8310\n",
      "Epoch 40/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.8878\n",
      "Epoch 40: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.8142 - accuracy: 0.8878 - val_loss: 0.9391 - val_accuracy: 0.8295\n",
      "Epoch 41/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8129 - accuracy: 0.8876\n",
      "Epoch 41: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.8129 - accuracy: 0.8876 - val_loss: 0.9985 - val_accuracy: 0.8114\n",
      "Epoch 42/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.8010 - accuracy: 0.8941\n",
      "Epoch 42: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.8010 - accuracy: 0.8941 - val_loss: 1.0176 - val_accuracy: 0.8000\n",
      "Epoch 43/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.8984\n",
      "Epoch 43: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7929 - accuracy: 0.8984 - val_loss: 1.0327 - val_accuracy: 0.7923\n",
      "Epoch 44/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.8989\n",
      "Epoch 44: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7884 - accuracy: 0.8989 - val_loss: 0.9798 - val_accuracy: 0.8209\n",
      "Epoch 45/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.8978\n",
      "Epoch 45: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 0.7921 - accuracy: 0.8978 - val_loss: 0.9918 - val_accuracy: 0.8128\n",
      "Epoch 46/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.9037\n",
      "Epoch 46: val_accuracy did not improve from 0.83100\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7796 - accuracy: 0.9037 - val_loss: 1.0267 - val_accuracy: 0.7996\n",
      "Epoch 47/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7794 - accuracy: 0.9048\n",
      "Epoch 47: val_accuracy improved from 0.83100 to 0.84510, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0047.ckpt\n",
      "79/79 [==============================] - 13s 160ms/step - loss: 0.7794 - accuracy: 0.9048 - val_loss: 0.9104 - val_accuracy: 0.8451\n",
      "Epoch 48/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.9025\n",
      "Epoch 48: val_accuracy did not improve from 0.84510\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 0.7790 - accuracy: 0.9025 - val_loss: 0.9264 - val_accuracy: 0.8415\n",
      "Epoch 49/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.9073\n",
      "Epoch 49: val_accuracy improved from 0.84510 to 0.84920, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0049.ckpt\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 0.7738 - accuracy: 0.9073 - val_loss: 0.9123 - val_accuracy: 0.8492\n",
      "Epoch 50/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.9107\n",
      "Epoch 50: val_accuracy did not improve from 0.84920\n",
      "79/79 [==============================] - 12s 157ms/step - loss: 0.7676 - accuracy: 0.9107 - val_loss: 0.9707 - val_accuracy: 0.8255\n",
      "Epoch 51/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.9086\n",
      "Epoch 51: val_accuracy did not improve from 0.84920\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 0.7683 - accuracy: 0.9086 - val_loss: 0.9352 - val_accuracy: 0.8410\n",
      "Epoch 52/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.9143\n",
      "Epoch 52: val_accuracy improved from 0.84920 to 0.84980, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0052.ckpt\n",
      "79/79 [==============================] - 13s 164ms/step - loss: 0.7601 - accuracy: 0.9143 - val_loss: 0.9075 - val_accuracy: 0.8498\n",
      "Epoch 53/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7571 - accuracy: 0.9140\n",
      "Epoch 53: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.7571 - accuracy: 0.9140 - val_loss: 0.9165 - val_accuracy: 0.8463\n",
      "Epoch 54/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7549 - accuracy: 0.9164\n",
      "Epoch 54: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7549 - accuracy: 0.9164 - val_loss: 0.9486 - val_accuracy: 0.8354\n",
      "Epoch 55/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.9161\n",
      "Epoch 55: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.7538 - accuracy: 0.9161 - val_loss: 0.9687 - val_accuracy: 0.8257\n",
      "Epoch 56/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.9193\n",
      "Epoch 56: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.7465 - accuracy: 0.9193 - val_loss: 0.9578 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.9199\n",
      "Epoch 57: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 0.7460 - accuracy: 0.9199 - val_loss: 0.9861 - val_accuracy: 0.8225\n",
      "Epoch 58/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.9240\n",
      "Epoch 58: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7378 - accuracy: 0.9240 - val_loss: 0.9098 - val_accuracy: 0.8482\n",
      "Epoch 59/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7306 - accuracy: 0.9264\n",
      "Epoch 59: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7306 - accuracy: 0.9264 - val_loss: 0.9393 - val_accuracy: 0.8386\n",
      "Epoch 60/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.9186\n",
      "Epoch 60: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7498 - accuracy: 0.9186 - val_loss: 0.9729 - val_accuracy: 0.8296\n",
      "Epoch 61/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7361 - accuracy: 0.9238\n",
      "Epoch 61: val_accuracy did not improve from 0.84980\n",
      "79/79 [==============================] - 12s 154ms/step - loss: 0.7361 - accuracy: 0.9238 - val_loss: 0.9804 - val_accuracy: 0.8265\n",
      "Epoch 62/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7358 - accuracy: 0.9257\n",
      "Epoch 62: val_accuracy improved from 0.84980 to 0.85060, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0062.ckpt\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 0.7358 - accuracy: 0.9257 - val_loss: 0.9114 - val_accuracy: 0.8506\n",
      "Epoch 63/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.9285\n",
      "Epoch 63: val_accuracy did not improve from 0.85060\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.7289 - accuracy: 0.9285 - val_loss: 0.9138 - val_accuracy: 0.8480\n",
      "Epoch 64/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.9280\n",
      "Epoch 64: val_accuracy did not improve from 0.85060\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7302 - accuracy: 0.9280 - val_loss: 0.9400 - val_accuracy: 0.8423\n",
      "Epoch 65/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7306 - accuracy: 0.9265\n",
      "Epoch 65: val_accuracy did not improve from 0.85060\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7306 - accuracy: 0.9265 - val_loss: 0.9365 - val_accuracy: 0.8439\n",
      "Epoch 66/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.9353\n",
      "Epoch 66: val_accuracy improved from 0.85060 to 0.86310, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0066.ckpt\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 0.7171 - accuracy: 0.9353 - val_loss: 0.8813 - val_accuracy: 0.8631\n",
      "Epoch 67/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.9349\n",
      "Epoch 67: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 0.7147 - accuracy: 0.9349 - val_loss: 0.9073 - val_accuracy: 0.8518\n",
      "Epoch 68/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7178 - accuracy: 0.9337\n",
      "Epoch 68: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 156ms/step - loss: 0.7178 - accuracy: 0.9337 - val_loss: 0.9845 - val_accuracy: 0.8298\n",
      "Epoch 69/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.9318\n",
      "Epoch 69: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.7226 - accuracy: 0.9318 - val_loss: 0.8970 - val_accuracy: 0.8562\n",
      "Epoch 70/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.9342\n",
      "Epoch 70: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.7195 - accuracy: 0.9342 - val_loss: 0.8943 - val_accuracy: 0.8597\n",
      "Epoch 71/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.9386\n",
      "Epoch 71: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.7056 - accuracy: 0.9386 - val_loss: 0.9507 - val_accuracy: 0.8382\n",
      "Epoch 72/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.9355\n",
      "Epoch 72: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.7140 - accuracy: 0.9355 - val_loss: 0.9780 - val_accuracy: 0.8204\n",
      "Epoch 73/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.9378\n",
      "Epoch 73: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.7087 - accuracy: 0.9378 - val_loss: 0.9085 - val_accuracy: 0.8558\n",
      "Epoch 74/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.9426\n",
      "Epoch 74: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7001 - accuracy: 0.9426 - val_loss: 0.9703 - val_accuracy: 0.8302\n",
      "Epoch 75/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.9391\n",
      "Epoch 75: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7066 - accuracy: 0.9391 - val_loss: 0.9011 - val_accuracy: 0.8556\n",
      "Epoch 76/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.9467\n",
      "Epoch 76: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6899 - accuracy: 0.9467 - val_loss: 0.9312 - val_accuracy: 0.8485\n",
      "Epoch 77/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.9354\n",
      "Epoch 77: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.7137 - accuracy: 0.9354 - val_loss: 0.8927 - val_accuracy: 0.8618\n",
      "Epoch 78/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.9446\n",
      "Epoch 78: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.6967 - accuracy: 0.9446 - val_loss: 0.9089 - val_accuracy: 0.8568\n",
      "Epoch 79/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.9460\n",
      "Epoch 79: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6931 - accuracy: 0.9460 - val_loss: 0.9320 - val_accuracy: 0.8482\n",
      "Epoch 80/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.9455\n",
      "Epoch 80: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.6941 - accuracy: 0.9455 - val_loss: 0.9093 - val_accuracy: 0.8565\n",
      "Epoch 81/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.9415\n",
      "Epoch 81: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.7025 - accuracy: 0.9415 - val_loss: 0.9157 - val_accuracy: 0.8519\n",
      "Epoch 82/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.9474\n",
      "Epoch 82: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6906 - accuracy: 0.9474 - val_loss: 0.9768 - val_accuracy: 0.8234\n",
      "Epoch 83/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.9462\n",
      "Epoch 83: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6911 - accuracy: 0.9462 - val_loss: 0.9026 - val_accuracy: 0.8593\n",
      "Epoch 84/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.9506\n",
      "Epoch 84: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6808 - accuracy: 0.9506 - val_loss: 0.9382 - val_accuracy: 0.8452\n",
      "Epoch 85/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.9490\n",
      "Epoch 85: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6866 - accuracy: 0.9490 - val_loss: 0.9100 - val_accuracy: 0.8556\n",
      "Epoch 86/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.9489\n",
      "Epoch 86: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6855 - accuracy: 0.9489 - val_loss: 0.9166 - val_accuracy: 0.8559\n",
      "Epoch 87/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.9507\n",
      "Epoch 87: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6803 - accuracy: 0.9507 - val_loss: 0.9115 - val_accuracy: 0.8596\n",
      "Epoch 88/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.9497\n",
      "Epoch 88: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6844 - accuracy: 0.9497 - val_loss: 0.8998 - val_accuracy: 0.8611\n",
      "Epoch 89/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.9573\n",
      "Epoch 89: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 148ms/step - loss: 0.6706 - accuracy: 0.9573 - val_loss: 0.9223 - val_accuracy: 0.8537\n",
      "Epoch 90/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.9479\n",
      "Epoch 90: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6871 - accuracy: 0.9479 - val_loss: 0.9141 - val_accuracy: 0.8555\n",
      "Epoch 91/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.9542\n",
      "Epoch 91: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6745 - accuracy: 0.9542 - val_loss: 0.9338 - val_accuracy: 0.8534\n",
      "Epoch 92/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.9506\n",
      "Epoch 92: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6828 - accuracy: 0.9506 - val_loss: 0.9580 - val_accuracy: 0.8480\n",
      "Epoch 93/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.9472\n",
      "Epoch 93: val_accuracy did not improve from 0.86310\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 0.6874 - accuracy: 0.9472 - val_loss: 0.9017 - val_accuracy: 0.8621\n",
      "Epoch 94/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.9585\n",
      "Epoch 94: val_accuracy improved from 0.86310 to 0.87360, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0094.ckpt\n",
      "79/79 [==============================] - 13s 165ms/step - loss: 0.6647 - accuracy: 0.9585 - val_loss: 0.8718 - val_accuracy: 0.8736\n",
      "Epoch 95/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.9525\n",
      "Epoch 95: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.6791 - accuracy: 0.9525 - val_loss: 0.9021 - val_accuracy: 0.8607\n",
      "Epoch 96/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.9553\n",
      "Epoch 96: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6732 - accuracy: 0.9553 - val_loss: 0.9187 - val_accuracy: 0.8557\n",
      "Epoch 97/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.9585\n",
      "Epoch 97: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6650 - accuracy: 0.9585 - val_loss: 0.9878 - val_accuracy: 0.8314\n",
      "Epoch 98/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.9535\n",
      "Epoch 98: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6762 - accuracy: 0.9535 - val_loss: 0.8752 - val_accuracy: 0.8717\n",
      "Epoch 99/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6711 - accuracy: 0.9574\n",
      "Epoch 99: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6711 - accuracy: 0.9574 - val_loss: 0.9751 - val_accuracy: 0.8425\n",
      "Epoch 100/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.9577\n",
      "Epoch 100: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 0.6683 - accuracy: 0.9577 - val_loss: 0.9360 - val_accuracy: 0.8548\n",
      "Epoch 101/150\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.6638 - accuracy: 0.9595\n",
      "Epoch 101: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6637 - accuracy: 0.9596 - val_loss: 0.9273 - val_accuracy: 0.8541\n",
      "Epoch 102/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.9588\n",
      "Epoch 102: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6660 - accuracy: 0.9588 - val_loss: 0.9208 - val_accuracy: 0.8581\n",
      "Epoch 103/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.9609\n",
      "Epoch 103: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6620 - accuracy: 0.9609 - val_loss: 0.9253 - val_accuracy: 0.8558\n",
      "Epoch 104/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.9545\n",
      "Epoch 104: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6744 - accuracy: 0.9545 - val_loss: 0.9197 - val_accuracy: 0.8582\n",
      "Epoch 105/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.9568\n",
      "Epoch 105: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6690 - accuracy: 0.9568 - val_loss: 0.8959 - val_accuracy: 0.8664\n",
      "Epoch 106/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.9612\n",
      "Epoch 106: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6594 - accuracy: 0.9612 - val_loss: 0.9555 - val_accuracy: 0.8428\n",
      "Epoch 107/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6669 - accuracy: 0.9583\n",
      "Epoch 107: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6669 - accuracy: 0.9583 - val_loss: 0.9196 - val_accuracy: 0.8605\n",
      "Epoch 108/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.9597\n",
      "Epoch 108: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 0.6645 - accuracy: 0.9597 - val_loss: 0.8986 - val_accuracy: 0.8698\n",
      "Epoch 109/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.9586\n",
      "Epoch 109: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6654 - accuracy: 0.9586 - val_loss: 0.8995 - val_accuracy: 0.8652\n",
      "Epoch 110/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.9657\n",
      "Epoch 110: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6526 - accuracy: 0.9657 - val_loss: 0.9419 - val_accuracy: 0.8498\n",
      "Epoch 111/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.9630\n",
      "Epoch 111: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6577 - accuracy: 0.9630 - val_loss: 0.9053 - val_accuracy: 0.8658\n",
      "Epoch 112/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.9625\n",
      "Epoch 112: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6596 - accuracy: 0.9625 - val_loss: 0.9433 - val_accuracy: 0.8533\n",
      "Epoch 113/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6556 - accuracy: 0.9645\n",
      "Epoch 113: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6556 - accuracy: 0.9645 - val_loss: 0.9030 - val_accuracy: 0.8639\n",
      "Epoch 114/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.9628\n",
      "Epoch 114: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6576 - accuracy: 0.9628 - val_loss: 0.9107 - val_accuracy: 0.8645\n",
      "Epoch 115/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6534 - accuracy: 0.9646\n",
      "Epoch 115: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 0.6534 - accuracy: 0.9646 - val_loss: 0.9221 - val_accuracy: 0.8616\n",
      "Epoch 116/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.9618\n",
      "Epoch 116: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6592 - accuracy: 0.9618 - val_loss: 0.9016 - val_accuracy: 0.8714\n",
      "Epoch 117/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.9672\n",
      "Epoch 117: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6490 - accuracy: 0.9672 - val_loss: 0.8820 - val_accuracy: 0.8728\n",
      "Epoch 118/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.9675\n",
      "Epoch 118: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6477 - accuracy: 0.9675 - val_loss: 0.9017 - val_accuracy: 0.8723\n",
      "Epoch 119/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.9628\n",
      "Epoch 119: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.6584 - accuracy: 0.9628 - val_loss: 0.9060 - val_accuracy: 0.8657\n",
      "Epoch 120/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.9665\n",
      "Epoch 120: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6503 - accuracy: 0.9665 - val_loss: 0.9503 - val_accuracy: 0.8545\n",
      "Epoch 121/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.9651\n",
      "Epoch 121: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6506 - accuracy: 0.9651 - val_loss: 0.9094 - val_accuracy: 0.8677\n",
      "Epoch 122/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.9648\n",
      "Epoch 122: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6535 - accuracy: 0.9648 - val_loss: 0.9211 - val_accuracy: 0.8639\n",
      "Epoch 123/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.9678\n",
      "Epoch 123: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6470 - accuracy: 0.9678 - val_loss: 0.9391 - val_accuracy: 0.8653\n",
      "Epoch 124/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.9634\n",
      "Epoch 124: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6564 - accuracy: 0.9634 - val_loss: 0.9037 - val_accuracy: 0.8709\n",
      "Epoch 125/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.9667\n",
      "Epoch 125: val_accuracy did not improve from 0.87360\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.6494 - accuracy: 0.9667 - val_loss: 0.9061 - val_accuracy: 0.8676\n",
      "Epoch 126/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.9664\n",
      "Epoch 126: val_accuracy improved from 0.87360 to 0.87490, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0126.ckpt\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 0.6501 - accuracy: 0.9664 - val_loss: 0.8885 - val_accuracy: 0.8749\n",
      "Epoch 127/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.9689\n",
      "Epoch 127: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.6452 - accuracy: 0.9689 - val_loss: 0.9099 - val_accuracy: 0.8708\n",
      "Epoch 128/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.9635\n",
      "Epoch 128: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 13s 159ms/step - loss: 0.6587 - accuracy: 0.9635 - val_loss: 0.9317 - val_accuracy: 0.8604\n",
      "Epoch 129/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6428 - accuracy: 0.9707\n",
      "Epoch 129: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6428 - accuracy: 0.9707 - val_loss: 0.9327 - val_accuracy: 0.8605\n",
      "Epoch 130/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.9695\n",
      "Epoch 130: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6442 - accuracy: 0.9695 - val_loss: 0.9120 - val_accuracy: 0.8690\n",
      "Epoch 131/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.9702\n",
      "Epoch 131: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6446 - accuracy: 0.9702 - val_loss: 0.9474 - val_accuracy: 0.8502\n",
      "Epoch 132/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.9677\n",
      "Epoch 132: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6467 - accuracy: 0.9677 - val_loss: 0.9047 - val_accuracy: 0.8724\n",
      "Epoch 133/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.9669\n",
      "Epoch 133: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 149ms/step - loss: 0.6494 - accuracy: 0.9669 - val_loss: 0.9485 - val_accuracy: 0.8541\n",
      "Epoch 134/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6498 - accuracy: 0.9668\n",
      "Epoch 134: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6498 - accuracy: 0.9668 - val_loss: 0.9143 - val_accuracy: 0.8651\n",
      "Epoch 135/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.9726\n",
      "Epoch 135: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6383 - accuracy: 0.9726 - val_loss: 0.9256 - val_accuracy: 0.8600\n",
      "Epoch 136/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.9705\n",
      "Epoch 136: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6429 - accuracy: 0.9705 - val_loss: 0.9365 - val_accuracy: 0.8623\n",
      "Epoch 137/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.9684\n",
      "Epoch 137: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 153ms/step - loss: 0.6457 - accuracy: 0.9684 - val_loss: 0.9034 - val_accuracy: 0.8748\n",
      "Epoch 138/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6390 - accuracy: 0.9717\n",
      "Epoch 138: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6390 - accuracy: 0.9717 - val_loss: 1.1889 - val_accuracy: 0.7776\n",
      "Epoch 139/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.9695\n",
      "Epoch 139: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6447 - accuracy: 0.9695 - val_loss: 0.9011 - val_accuracy: 0.8712\n",
      "Epoch 140/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.9698\n",
      "Epoch 140: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.6455 - accuracy: 0.9698 - val_loss: 0.9141 - val_accuracy: 0.8685\n",
      "Epoch 141/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.9713\n",
      "Epoch 141: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.6410 - accuracy: 0.9713 - val_loss: 0.9165 - val_accuracy: 0.8683\n",
      "Epoch 142/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.9710\n",
      "Epoch 142: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6422 - accuracy: 0.9710 - val_loss: 0.9331 - val_accuracy: 0.8631\n",
      "Epoch 143/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.9592\n",
      "Epoch 143: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6685 - accuracy: 0.9592 - val_loss: 0.9201 - val_accuracy: 0.8703\n",
      "Epoch 144/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6417 - accuracy: 0.9717\n",
      "Epoch 144: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 152ms/step - loss: 0.6417 - accuracy: 0.9717 - val_loss: 0.9206 - val_accuracy: 0.8692\n",
      "Epoch 145/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.9724\n",
      "Epoch 145: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 151ms/step - loss: 0.6383 - accuracy: 0.9724 - val_loss: 0.9130 - val_accuracy: 0.8609\n",
      "Epoch 146/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.9726\n",
      "Epoch 146: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6386 - accuracy: 0.9726 - val_loss: 0.8983 - val_accuracy: 0.8716\n",
      "Epoch 147/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.9703\n",
      "Epoch 147: val_accuracy did not improve from 0.87490\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6410 - accuracy: 0.9703 - val_loss: 0.9118 - val_accuracy: 0.8677\n",
      "Epoch 148/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.9726\n",
      "Epoch 148: val_accuracy improved from 0.87490 to 0.88030, saving model to weights_V2/CustomizeLarge/SE_Adam_cifar10\\cp-0148.ckpt\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 0.6370 - accuracy: 0.9726 - val_loss: 0.8965 - val_accuracy: 0.8803\n",
      "Epoch 149/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.9742\n",
      "Epoch 149: val_accuracy did not improve from 0.88030\n",
      "79/79 [==============================] - 12s 155ms/step - loss: 0.6322 - accuracy: 0.9742 - val_loss: 0.8943 - val_accuracy: 0.8715\n",
      "Epoch 150/150\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.9748\n",
      "Epoch 150: val_accuracy did not improve from 0.88030\n",
      "79/79 [==============================] - 12s 150ms/step - loss: 0.6310 - accuracy: 0.9748 - val_loss: 0.9915 - val_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "if Dataset == \"325 Bird Species\" or Dataset == \"100 Bird Species\":\n",
    "    history_ft = model.fit(trainset,\n",
    "                        epochs=epoch_1,\n",
    "                        validation_data=valset,\n",
    "                        callbacks=callbacks,\n",
    "                        # verbose=0\n",
    "                        )\n",
    "elif Dataset == \"cifar10\" or Dataset == \"cifar100\":\n",
    "    history_ft = model.fit(datagen_train.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                            epochs=epoch_1,\n",
    "                            validation_data=datagen_val.flow(x_val, y_val, batch_size=BATCH_SIZE),\n",
    "                            callbacks=callbacks,\n",
    "                            # verbose=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c3363",
   "metadata": {},
   "source": [
    "# Fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94587e1f",
   "metadata": {},
   "source": [
    "## 設定unfrozen的Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a841d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_to_transfer_learning(base_model, unfrozen=unfrozen)\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81d2f4",
   "metadata": {},
   "source": [
    "# Training-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b1ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Dataset == \"325 Bird Species\" or Dataset == \"100 Bird Species\":\n",
    "#     history_ft = model.fit(trainset,\n",
    "#                             epochs=epoch_1 + epoch_2,\n",
    "#                             initial_epoch=epoch_1,\n",
    "#                             validation_data=valset,\n",
    "#                             callbacks=callbacks)\n",
    "# elif Dataset == \"cifar10\" or Dataset == \"cifar100\":\n",
    "#     history_ft = model.fit(datagen_train.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "#                             epochs=epoch_1 + epoch_2,\n",
    "#                             initial_epoch=epoch_1,\n",
    "#                             validation_data=datagen_val.flow(x_val, y_val, batch_size=BATCH_SIZE),\n",
    "#                             callbacks=callbacks,\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e4ef2",
   "metadata": {},
   "source": [
    "# SAVE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0339a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine模型列表：\n",
      "checkpoint\n",
      "cp-0001.ckpt.data-00000-of-00001\n",
      "cp-0001.ckpt.index\n",
      "cp-0006.ckpt.data-00000-of-00001\n",
      "cp-0006.ckpt.index\n",
      "cp-0008.ckpt.data-00000-of-00001\n",
      "cp-0008.ckpt.index\n",
      "cp-0009.ckpt.data-00000-of-00001\n",
      "cp-0009.ckpt.index\n",
      "cp-0010.ckpt.data-00000-of-00001\n",
      "cp-0010.ckpt.index\n",
      "cp-0012.ckpt.data-00000-of-00001\n",
      "cp-0012.ckpt.index\n",
      "cp-0014.ckpt.data-00000-of-00001\n",
      "cp-0014.ckpt.index\n",
      "cp-0016.ckpt.data-00000-of-00001\n",
      "cp-0016.ckpt.index\n",
      "cp-0021.ckpt.data-00000-of-00001\n",
      "cp-0021.ckpt.index\n",
      "cp-0022.ckpt.data-00000-of-00001\n",
      "cp-0022.ckpt.index\n",
      "cp-0023.ckpt.data-00000-of-00001\n",
      "cp-0023.ckpt.index\n",
      "cp-0025.ckpt.data-00000-of-00001\n",
      "cp-0025.ckpt.index\n",
      "cp-0032.ckpt.data-00000-of-00001\n",
      "cp-0032.ckpt.index\n",
      "cp-0033.ckpt.data-00000-of-00001\n",
      "cp-0033.ckpt.index\n",
      "cp-0034.ckpt.data-00000-of-00001\n",
      "cp-0034.ckpt.index\n",
      "cp-0035.ckpt.data-00000-of-00001\n",
      "cp-0035.ckpt.index\n",
      "cp-0036.ckpt.data-00000-of-00001\n",
      "cp-0036.ckpt.index\n",
      "cp-0039.ckpt.data-00000-of-00001\n",
      "cp-0039.ckpt.index\n",
      "cp-0047.ckpt.data-00000-of-00001\n",
      "cp-0047.ckpt.index\n",
      "cp-0049.ckpt.data-00000-of-00001\n",
      "cp-0049.ckpt.index\n",
      "cp-0052.ckpt.data-00000-of-00001\n",
      "cp-0052.ckpt.index\n",
      "cp-0062.ckpt.data-00000-of-00001\n",
      "cp-0062.ckpt.index\n",
      "cp-0066.ckpt.data-00000-of-00001\n",
      "cp-0066.ckpt.index\n",
      "cp-0094.ckpt.data-00000-of-00001\n",
      "cp-0094.ckpt.index\n",
      "cp-0126.ckpt.data-00000-of-00001\n",
      "cp-0126.ckpt.index\n",
      "cp-0148.ckpt.data-00000-of-00001\n",
      "cp-0148.ckpt.index\n",
      "最新的model為： cp-0148.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = f'./weights_V2/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}'\n",
    "model_num = ''\n",
    "print('Fine模型列表：')\n",
    "for a in os.listdir(path):\n",
    "    print(a)\n",
    "    model_num = a\n",
    "print('最新的model為：',model_num)\n",
    "model_num = a[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf879d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x28697578490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f'./weights_V2/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}/{model_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fccc2fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as HardSigmoid_layer_call_fn, HardSigmoid_layer_call_and_return_conditional_losses, HardSigmoid_layer_call_fn, HardSigmoid_layer_call_and_return_conditional_losses, HardSigmoid_layer_call_fn while saving (showing 5 of 202). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./weights_V2/CustomizeLarge/SE_Adam_cifar10/best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./weights_V2/CustomizeLarge/SE_Adam_cifar10/best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f'./weights_V2/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}/best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea000d6",
   "metadata": {},
   "source": [
    "# TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e0fe367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as HardSigmoid_layer_call_fn, HardSigmoid_layer_call_and_return_conditional_losses, HardSigmoid_layer_call_fn, HardSigmoid_layer_call_and_return_conditional_losses, HardSigmoid_layer_call_fn while saving (showing 5 of 202). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpdauajrry\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpdauajrry\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# path to the SavedModel directory\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_dir = f'./weights_V2/{backbone}/{Attention_block_2}_{LR_mode}_{Dataset}/tflite/'\n",
    "if not os.path.isdir(tflite_dir):\n",
    "    os.makedirs(tflite_dir)\n",
    "\n",
    "# Save the model.\n",
    "with open(tflite_dir + \"model.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e0f5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# stepNum = len(y_test)\n",
    "# start = time.time()\n",
    "\n",
    "# #利用模型進行預測，記得輸入的test_generator的shuffle內建要是False\n",
    "# results = model.evaluate(x_test/255, y_test, batch_size=1)\n",
    "\n",
    "# end = time.time()\n",
    "# # Time elapsed\n",
    "# seconds = end - start\n",
    "# FPS = stepNum/seconds\n",
    "# print(\"FPS:\",FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5d734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf28')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a14233ad27c41d9efa5d823986c1abaab766fef9bf858d2cfb402480f07c8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
